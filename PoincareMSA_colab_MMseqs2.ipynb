{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/klanita/PoincareMSA/blob/master/PoincareMSA_colab_MMseqs2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5FTaqy0xqw2"
   },
   "source": [
    "<img src=\"https://github.com/klanita/PoincareMSA/blob/master/.github/PoincareMSA_small_logo.png?raw=true\" height=\"100\" style=\"height:100px;margin-left: 0px;\">\n",
    "\n",
    "# Poincaré maps for visualization of large protein famillies\n",
    "\n",
    "**Authors**: Anna Klimovskaia-Susmelj, Yani Ren, Yann Vander Meersche, Jean-Christophe Gelly and Tatiana Galochkina\n",
    "\n",
    "PoincaréMSA builds an interactive projection of an input protein multiple sequence alignemnt (MSA) using a method based on Poincaré maps described by Klimovskaia et al [1]. It reproduces both local proximities of protein sequences and hierarchy contained in give data. Thus, sequences located closer to the center of projection correspond to the proteins sharing the most general functional properites and/or appearing at the earlier stages of evolution. Source code is available at https://github.com/klanita/PoincareMSA.\n",
    "\n",
    "[1] Klimovskaia, A., Lopez-Paz, D., Bottou, L. et al. Poincaré maps for analyzing complex hierarchies in single-cell data. Nat Commun 11, 2966 (2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oa7Rrq-YzfQB"
   },
   "source": [
    "# Notebook initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "X_SO37g-kQq7"
   },
   "outputs": [],
   "source": [
    "#@title ### Load PoincaréMSA Github repository & install dependencies\n",
    "print(\"1. Load PoincaréMSA Github repository\")\n",
    "import os\n",
    "if os.getcwd() == \"/content\":\n",
    "    !git clone https://github.com/klanita/PoincareMSA.git\n",
    "    %cd PoincareMSA\n",
    "\n",
    "# Check if the GPU is activated\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('\\nUsing device:', device)\n",
    "\n",
    "#Install missing module\n",
    "print(\"\\n2. Install dependencies\")\n",
    "!pip install adjustText\n",
    "!pip install -U kaleido\n",
    "!pip install ncbi-taxonomist\n",
    "\n",
    "#Install HHfilter\n",
    "if not os.path.isdir(\"/content/hh-suite/\"):\n",
    "    !mkdir /content/hh-suite\n",
    "    %cd /content/hh-suite\n",
    "    !wget https://github.com/soedinglab/hh-suite/releases/download/v3.3.0/hhsuite-3.3.0-AVX2-Linux.tar.gz\n",
    "    !tar xfz hhsuite-3.3.0-AVX2-Linux.tar.gz\n",
    "    %cd /content/PoincareMSA/\n",
    "    print(\"HH-suite correctly installed.\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#File import\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "#Import visualization functions\n",
    "from scripts.visualize_projection.pplots_new import read_embeddings, plot_embedding, plot_embedding_interactive, rotate, get_colors\n",
    "from scripts.prepare_data.mmseqs2_api import run_mmseqs2\n",
    "from scripts.prepare_data.uniprot_idmapping_api import submit_id_mapping, check_id_mapping_results_ready, get_id_mapping_results_link, get_id_mapping_results_search\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "GcbgnooHwIGh"
   },
   "outputs": [],
   "source": [
    "#@title # Compute MSA with MMseqs2\n",
    "sequence = \"GGTLAIQAQGDLTLAQKKIVRKTWHQLMRNKTSFVTDVFIRIFAYDPSAQNKFPQMAGMSASQLRSSRQMQAHAIRVSSIMSEYVEELDSDILPELLATLARTHDLNKVGADHYNLFAKVLMEALQAELGSDFNEKTRDAWAKAFSVVQAVLLVKHGN\" #@param {type:\"string\"}\n",
    "#@markdown Maximum pairwise sequence identity (%) [0-100].\n",
    "seq_identity = 50 #@param {type:\"number\"}\n",
    "#@markdown Minimum coverage with query (%) [0-100].\n",
    "cov = 75 #@param {type:\"number\"}\n",
    "#@markdown Target diversity of alignment [1,inf].\n",
    "neff = 7 #@param {type:\"number\"}\n",
    "\n",
    "if os.path.isdir(\"_env\"):\n",
    "    !rm -rf _env\n",
    "msa = run_mmseqs2(sequence, \"./\")\n",
    "\n",
    "nb_seq = 0\n",
    "mfasta = \"_env/uniref.a3m\"\n",
    "with open(mfasta, \"r\") as f_in:\n",
    "    for line in f_in:\n",
    "        if line[0] == \">\":\n",
    "            nb_seq += 1\n",
    "\n",
    "#Use HHFilter to reduce sequence identity\n",
    "!/content/hh-suite/bin/hhfilter -i $mfasta -o _env/uniref_filtered.a3m -id $seq_identity -cov $cov -neff $neff -v 0\n",
    "#Convert a3m to mfasta\n",
    "!/content/hh-suite/scripts/reformat.pl a3m fas _env/uniref_filtered.a3m _env/uniref_filtered.mfasta -v 0\n",
    "\n",
    "UnP_ids = []\n",
    "nb_fseq = 0\n",
    "mfasta = \"_env/uniref_filtered.mfasta\"\n",
    "with open(mfasta, \"r\") as f_in:\n",
    "    for line in f_in:\n",
    "        if line[0] == \">\":\n",
    "            nb_fseq += 1\n",
    "            UnP_ids.append(line[1:].split()[0])\n",
    "\n",
    "#Split UniProtKB and UniParc IDs\n",
    "uniparc_ids = []\n",
    "uniprot_ids = []\n",
    "for unp in UnP_ids:\n",
    "    if len(unp) == 13 and unp[:2] == \"UP\":\n",
    "        uniparc_ids.append(unp)\n",
    "    elif unp == \"101\":\n",
    "        pass\n",
    "    else:\n",
    "        uniprot_ids.append(unp)\n",
    "\n",
    "#Fetch UniProtKB annotations\n",
    "job_id = submit_id_mapping(\n",
    "    from_db=\"UniProtKB_AC-ID\", to_db=\"UniParc\", ids=uniprot_ids\n",
    ")\n",
    "\n",
    "if check_id_mapping_results_ready(job_id):\n",
    "    link = get_id_mapping_results_link(job_id)\n",
    "    results = get_id_mapping_results_search(link)\n",
    "\n",
    "#Fetch UniParc annotations\n",
    "job_id = submit_id_mapping(\n",
    "    from_db=\"UniParc\", to_db=\"UniParc\", ids=uniparc_ids\n",
    ")\n",
    "\n",
    "if check_id_mapping_results_ready(job_id):\n",
    "    link = get_id_mapping_results_link(job_id)\n",
    "    results2 = get_id_mapping_results_search(link)\n",
    "\n",
    "#Create annotation dataframe\n",
    "df_annotation = pd.DataFrame(UnP_ids[1:], columns=[\"UnP_ID\"])\n",
    "df_annotation[\"organism\"] = \"\"\n",
    "df_annotation[\"proteinName\"] = \"\"\n",
    "df_annotation[\"taxonId\"] = \"\"\n",
    "df_annotation[\"species\"] = \"\"\n",
    "df_annotation[\"genus\"] = \"\"\n",
    "df_annotation[\"family\"] = \"\"\n",
    "df_annotation[\"order\"] = \"\"\n",
    "df_annotation[\"class\"] = \"\"\n",
    "df_annotation[\"phylum\"] = \"\"\n",
    "df_annotation[\"clade\"] = \"\"\n",
    "df_annotation[\"superkingdom\"] = \"\"\n",
    "\n",
    "#Fill the annotation DataFrame\n",
    "for dict_res in results[\"results\"] + results2[\"results\"]:\n",
    "    try:\n",
    "        unp = dict_res[\"from\"]\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        prot_name = dict_res[\"to\"][\"uniParcCrossReferences\"][0][\"proteinName\"]\n",
    "        df_annotation.loc[df_annotation[\"UnP_ID\"] == unp, \"proteinName\"] = prot_name\n",
    "    except KeyError:\n",
    "        continue\n",
    "    try:\n",
    "        scientific_name = dict_res[\"to\"][\"uniParcCrossReferences\"][0][\"organism\"][\"scientificName\"]\n",
    "        taxid = dict_res[\"to\"][\"uniParcCrossReferences\"][0][\"organism\"][\"taxonId\"]\n",
    "        df_annotation.loc[df_annotation[\"UnP_ID\"] == unp, \"organism\"] = scientific_name\n",
    "        df_annotation.loc[df_annotation[\"UnP_ID\"] == unp, \"taxonId\"] = taxid\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "#Add lineage from NCBI Taxonomist\n",
    "taxon_ids = df_annotation.loc[df_annotation[\"taxonId\"].notnull(), 'taxonId'].to_numpy()\n",
    "taxon_ids = list(set(taxon_ids))\n",
    "taxon_ids = list(map(str, taxon_ids))\n",
    "bash_command = f\"ncbi-taxonomist resolve -t {','.join(taxon_ids)}\"\n",
    "\n",
    "list_taxon = subprocess.run(bash_command, shell=True, capture_output=True, text=True).stdout.strip().split(\"\\n\")\n",
    "\n",
    "for taxon in list_taxon:\n",
    "    jsonString = taxon\n",
    "    taxon_dict = json.loads(jsonString)\n",
    "    query = taxon_dict[\"query\"]\n",
    "    for lineage in taxon_dict[\"lineage\"]:\n",
    "\n",
    "        rank = lineage[\"rank\"]\n",
    "\n",
    "        if rank in [\"species\", \"genus\", \"family\", \"order\", \"class\", \"phylum\", \"clade\", \"superkingdom\"]:\n",
    "            name = lineage[\"name\"]\n",
    "            df_annotation.loc[df_annotation[\"taxonId\"] == int(query), rank] = name\n",
    "\n",
    "#Add query line in the DataFrame\n",
    "df_annotation.loc[-1] = ['query', 'query', 'query', \"query\", 'query', 'query', 'query', \"query\", 'query', 'query', 'query', 'query']\n",
    "df_annotation.index = df_annotation.index + 1\n",
    "df_annotation.sort_index(inplace=True) \n",
    "\n",
    "#Save annotation to csv\n",
    "path_annotation = \"auto_annot.csv\"\n",
    "df_annotation.to_csv(path_annotation, index=False)\n",
    "annotation_names = [\"proteins_id\"] + list(df_annotation.columns)\n",
    "\n",
    "print(f\"\\nNumber of sequences found: {nb_seq}.\")\n",
    "print(f\"Number of filtered sequences: {nb_fseq}.\")\n",
    "\n",
    "nb_seq = nb_fseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H2vnIt_3kUz"
   },
   "source": [
    "# Data preparation\n",
    "Here we clean the input .mfasta alignment and translate each sequence to a vector ready for projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "9hLq_MgX6hFC"
   },
   "outputs": [],
   "source": [
    "#@title ## Parameters for data preparation\n",
    "#@markdown ### Job name\n",
    "#@markdown Name for the output folder\n",
    "out_name = \"poincareMSA\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Threshold for filtering gapped positions\n",
    "#@markdown Positions with proportion of gaps above the given threshold are removed from the alignment. If your alignment is very gapped, you may want to increase this value.\n",
    "gapth = 0.9 #@param {type:\"number\"}\n",
    "\n",
    "#@markdown ## Run data preparation\n",
    "#@markdown Data preparation consists in `.mfasta` cleaning according to a gap threshold and translation of each sequence to the PSSM profile.\n",
    "\n",
    "print(\"1. Data preparation\")\n",
    "prep_parameters = \"scripts/prepare_data\" + \" \" + mfasta + \" \" + out_name + \" \" + out_name + \" \" + str(gapth)\n",
    "bash_projection = \"bash scripts/prepare_data/create_projection.sh \" + prep_parameters\n",
    "!{bash_projection}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dv0lg4Jn-dfG"
   },
   "source": [
    "# Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "collapsed": true,
    "id": "B2_Cm3P9DJjD"
   },
   "outputs": [],
   "source": [
    "#@title ### Projection parameters\n",
    "#@markdown Here you control different parameters of Poincaré maps. In our computational experiments the best results were achieved for the following values provided by default. The impact of different parameters is analyzed in the original paper [1].\n",
    "knn = 5 #@param {type:\"number\"}\n",
    "gamma = 2 #@param {type:\"number\"}\n",
    "sigma = 1 #@param {type:\"number\"}\n",
    "cospca = 0 #@param {type:\"number\"}\n",
    "batchs = 4 #@param {type:\"number\"}\n",
    "epochs = 1000 #@param {type:\"number\"}\n",
    "seed = 0 #@param {type:\"number\"}\n",
    "\n",
    "\n",
    "print(\"\\n2. Data projection using Poincaré disk\")\n",
    "#@markdown ## Building projection and preparing data for visualization\n",
    "#@markdown This step creates a projection of encoded sequences to a Poincaré disk.\n",
    "bash_pm = \"python3 \"+ \"scripts/build_poincare_map/main.py --input_path \" + out_name + \"/fasta\" + str(gapth) + \" --output_path \" + out_name + \"/projections/ --gamma \"+ str(gamma) +\" --pca \"+ str(cospca) + \" --epochs \"+ str(epochs) +\" --seed \"+ str(seed) + \" --knn \" + str(knn)\n",
    "!{bash_pm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRxHHfjX7CHF"
   },
   "source": [
    "# Projection visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "hm_w-BlvTSVY"
   },
   "outputs": [],
   "source": [
    "#@title ### Prepare data for visualization\n",
    "#@markdown Check if the annotation file is provided and prepares a dataframe for visualization.\n",
    "\n",
    "#print(\"\\n3. Format data for visualization\")\n",
    "#Check that an annotation file was provided. Create a dummy one instead\n",
    "if not path_annotation:\n",
    "    df_annotation = pd.DataFrame(list(range(1,nb_seq+1)), columns=[\"id\"], dtype=\"float\")\n",
    "    df_annotation.to_csv(\"dummy_annotation.csv\", index=False)\n",
    "    path_annotation = \"dummy_annotation.csv\"\n",
    "    annotation_names = [\"id\"]\n",
    "\n",
    "#Create the DataFrame for visualization\n",
    "path_embedding = f\"{out_name}/projections/PM{knn:1.0f}sigma={sigma:2.2f}gamma={gamma:2.2f}cosinepca={cospca:1.0f}_seed{seed:1.0f}.csv\"\n",
    "df_embedding = read_embeddings(path_embedding, path_annotation, withroot=False)\n",
    "\n",
    "#@markdown Here are different labels found in your annotation file (if one uploaded):\n",
    "print(f\"{len(annotation_names)} annotations found: {annotation_names}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "zLb9h9S4eKUD"
   },
   "outputs": [],
   "source": [
    "#@title ### Create interactive plot\n",
    "#@markdown Here you can set different parameters to color & annotate the resulting projection:\n",
    "\n",
    "title = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#Labels name\n",
    "#@markdown ---\n",
    "#@markdown #### Select the coloring from annotation .csv file:\n",
    "labels_name = \"\" #@param {type:\"string\"}\n",
    "if labels_name == \"\":\n",
    "    labels_name = None\n",
    "elif labels_name not in annotation_names:\n",
    "    raise NameError(f\"labels_name {labels_name} is not in the availables annotations.\\nAvailables annotations: {annotation_names}\")\n",
    "\n",
    "#Labels text\n",
    "#@markdown #### Select classes to label among the \"labels_name\" or \"second_labels_name\" column (comma separated list):\n",
    "second_labels_name = \"\" #@param {type:\"string\"}\n",
    "if second_labels_name == \"\":\n",
    "    second_labels_name = None\n",
    "elif second_labels_name not in annotation_names:\n",
    "    raise NameError(f'\"second_labels_name\" {second_labels_name} is not in the availables annotations.\\nAvailables annotations: {annotation_names}')\n",
    "\n",
    "\n",
    "labels_text = \"\" #@param {type:\"string\"}\n",
    "if labels_text:\n",
    "    try:\n",
    "        labels_text = [s.strip() for s in labels_text.split(\",\")]\n",
    "    except:\n",
    "        print('Error: \"label_text\" field is not a valid list.')\n",
    "else:\n",
    "    labels_text = [\"\"]\n",
    "\n",
    "#Convert labels_text to labels_name dtype\n",
    "if labels_name and second_labels_name is None:\n",
    "    if labels_name and labels_text != [\"\"]:\n",
    "        try:\n",
    "            labels_text_dtype = df_annotation[labels_name].dtypes\n",
    "            labels_text = list(np.array(labels_text).astype(labels_text_dtype))\n",
    "        except:\n",
    "            raise TypeError(f'\"labels_text\" is not compatible with {labels_name}\" data format ({labels_text_dtype}).')\n",
    "else:\n",
    "    if second_labels_name and labels_text != [\"\"]:\n",
    "        try:\n",
    "            labels_text_dtype = df_annotation[second_labels_name].dtypes\n",
    "            labels_text = list(np.array(labels_text).astype(labels_text_dtype))\n",
    "        except:\n",
    "            raise TypeError(f'\"labels_text\" is not compatible with {second_labels_name}\" data format ({labels_text_dtype}).')\n",
    "\n",
    "show_text = True #@param {type:\"boolean\"}\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown #### Use a custom color palette:\n",
    "color_palette = None #@param {type:\"raw\"}\n",
    "use_custom_palette = False #@param {type:\"boolean\"}\n",
    "\n",
    "if not use_custom_palette:\n",
    "    color_palette = None\n",
    "\n",
    "#Plot graph\n",
    "fig = plot_embedding_interactive(df_embedding, \n",
    "                                 labels_name = labels_name,\n",
    "                                 second_labels_name = second_labels_name, \n",
    "                                 show_text = show_text,\n",
    "                                 labels_text = labels_text,\n",
    "                                 color_palette = color_palette, \n",
    "                                 title = title, \n",
    "                                 fontsize = 11)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "CGaefRbSWA0d"
   },
   "outputs": [],
   "source": [
    "#@title Save plot to file\n",
    "output_name = \"figure\" #@param {type:\"string\"}\n",
    "output_format = \"html\" #@param [\"png\", \"html\", \"pdf\", \"svg\"]\n",
    "\n",
    "if output_format != \"html\":\n",
    "    fig.write_image(f\"{output_name}.{output_format}\", engine=\"kaleido\")\n",
    "else:\n",
    "    fig.write_html(f\"{output_name}.{output_format}\")\n",
    "files.download(f\"{output_name}.{output_format}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "KB6XdhXCWA0d"
   },
   "outputs": [],
   "source": [
    "#@title Download intermediate data\n",
    "bash_command = f\"zip -r -q {out_name}.zip {out_name}\"\n",
    "!{bash_command}\n",
    "\n",
    "files.download(f\"{out_name}.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCodoZxXWA0d"
   },
   "source": [
    "# Help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlwImUjbN_CG"
   },
   "source": [
    "### Enabling the GPU\n",
    "\n",
    "To enable GPU in your notebook, select the following menu options −\n",
    "```\n",
    "Runtime / Change runtime type\n",
    "```\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"https://github.com/klanita/PoincareMSA/blob/master/.github/colab_gpu.png?raw=true\" width=500>\n",
    "</center>\n",
    "</figure>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
